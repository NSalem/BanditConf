# BanditConf
Modeling choice and confidence in reinforcement learning (restless bandits) with Gaussian-distributed payoffs. The data are those used by [Hertz et al (2018)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0195399)

The experiment consists on a non-stationary two-armed bandit task. At each trial, participants are presented with two doors, and have to choose one of them, and indicate their level of confidence (1 to 6) as below:
<img src="./HertzTrial.PNG">

There are 4 blocks (actually more but not reported), for which 
<img src="./HertzConditions_Exp1.PNG">


[comment]: #(![f1] use something like this to insert formulas)
[f1]: http://chart.apis.google.com/chart?cht=tx&chl=\alpha
